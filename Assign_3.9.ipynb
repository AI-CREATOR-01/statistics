{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a621c6f0",
   "metadata": {},
   "source": [
    "Q1: What are the Probability Mass Function (PMF) and Probability Density Function (PDF)? Explain with\n",
    "an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0788bf89",
   "metadata": {},
   "source": [
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are used to describe the probability distribution of a random variable in probability theory and statistics.\n",
    "\n",
    "A Probability Mass Function (PMF) is used to describe the probability distribution of a discrete random variable. It gives the probability that a discrete random variable takes on a specific value. The PMF is defined as the function that maps each possible value of the discrete random variable to its probability.\n",
    "\n",
    "For example, suppose we toss a fair six-sided die. The possible values that the die can take are {1, 2, 3, 4, 5, 6}. The PMF of the random variable X representing the number that comes up on the die is given by:\n",
    "\n",
    "P(X = 1) = 1/6\n",
    "P(X = 2) = 1/6\n",
    "P(X = 3) = 1/6\n",
    "P(X = 4) = 1/6\n",
    "P(X = 5) = 1/6\n",
    "P(X = 6) = 1/6\n",
    "\n",
    "The sum of all probabilities must equal 1, which is the total probability of all possible outcomes.\n",
    "\n",
    "On the other hand, a Probability Density Function (PDF) is used to describe the probability distribution of a continuous random variable. It gives the probability that a continuous random variable takes on a value in a given range. Unlike PMF, PDF is not defined at any specific value of a continuous random variable, but rather gives the probability density at any given point.\n",
    "\n",
    "For example, suppose the height of students in a class follows a normal distribution. We can use a PDF to describe the probability density of the heights. The PDF of the random variable X representing the height of students can be given by:\n",
    "\n",
    "f(x) = 1/(σ√(2π)) * e^-(x-μ)^2/(2σ^2)\n",
    "\n",
    "where μ is the mean of the distribution, σ is the standard deviation, and e is the natural logarithm base. This function gives the probability density of the height of a student at any given point x.\n",
    "\n",
    "Note that the area under the curve of the PDF over a certain range gives the probability of the continuous random variable taking a value within that range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41bc435",
   "metadata": {},
   "source": [
    "Q2: What is Cumulative Density Function (CDF)? Explain with an example. Why CDF is used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2ea3c0",
   "metadata": {},
   "source": [
    "The Cumulative Density Function (CDF) is a mathematical function used to describe the probability distribution of a random variable. It gives the probability that a random variable X will take a value less than or equal to x.\n",
    "\n",
    "In other words, CDF is the probability of a value of a random variable being less than or equal to a given value. It is defined as:\n",
    "\n",
    "F(x) = P(X <= x)\n",
    "\n",
    "where F(x) is the cumulative distribution function, X is a random variable, and x is the value of the random variable.\n",
    "\n",
    "For example, let's consider the roll of a fair six-sided die. The probability of getting a specific value on the die is 1/6, and the probability of getting a value less than or equal to a given value x is:\n",
    "\n",
    "F(x) = P(X <= x) = x/6\n",
    "\n",
    "For instance, the probability of rolling a value less than or equal to 4 is F(4) = 4/6 = 0.67.\n",
    "\n",
    "CDF is used to determine the likelihood of a random variable taking on a specific value or falling within a specific range of values. It provides a complete picture of the distribution of a random variable and is often used in statistical analysis to calculate probabilities and make predictions. CDF is also used to find the median and quartiles of a distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f02ce7",
   "metadata": {},
   "source": [
    "Q3: What are some examples of situations where the normal distribution might be used as a model?\n",
    "Explain how the parameters of the normal distribution relate to the shape of the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a81f7c1",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution, is a probability distribution that is widely used as a model in many fields of science, engineering, and social sciences. Some examples of situations where the normal distribution might be used as a model are:\n",
    "\n",
    "IQ scores: IQ scores are known to follow a normal distribution with a mean of 100 and a standard deviation of 15.\n",
    "\n",
    "Height and weight: The height and weight of a population also follow a normal distribution.\n",
    "\n",
    "Error terms in regression analysis: The error terms in linear regression models are often assumed to be normally distributed.\n",
    "\n",
    "Stock prices: Daily returns of stocks are often modeled using a normal distribution.\n",
    "\n",
    "The parameters of the normal distribution are the mean and the standard deviation. The mean is the center of the distribution and determines where the peak of the curve is located. The standard deviation determines the spread of the curve. A larger standard deviation indicates that the values are more spread out from the mean, while a smaller standard deviation indicates that the values are more tightly clustered around the mean.\n",
    "\n",
    "For example, if we have a normal distribution with a mean of 50 and a standard deviation of 10, the majority of the values will be clustered around the mean of 50, and the curve will be relatively narrow. On the other hand, if we have a normal distribution with a mean of 50 and a standard deviation of 20, the values will be more spread out from the mean, and the curve will be wider.\n",
    "\n",
    "The normal distribution is often described as a bell-shaped curve because of its characteristic shape, where the majority of the data is clustered around the mean, and the values become increasingly rare as they move away from the mean in either direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28949526",
   "metadata": {},
   "source": [
    "Q4: Explain the importance of Normal Distribution. Give a few real-life examples of Normal\n",
    "Distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d75378",
   "metadata": {},
   "source": [
    "The normal distribution, also known as the Gaussian distribution, is an important statistical concept in various fields of study. Some of the key reasons why the normal distribution is important are:\n",
    "\n",
    "Central Limit Theorem: The normal distribution is a fundamental concept in probability theory, and it plays a crucial role in the Central Limit Theorem, which states that the distribution of the sum of a large number of independent and identically distributed random variables tends towards a normal distribution. This theorem is widely used in statistical inference to estimate population parameters from sample data.\n",
    "\n",
    "Modeling Real-World Data: The normal distribution is commonly used to model real-world data that are approximately symmetric and bell-shaped. It allows us to understand and describe the variation in data, calculate probabilities, and make predictions about future observations.\n",
    "\n",
    "Inferential Statistics: The normal distribution is important in inferential statistics, where we use sample data to make inferences about a population. Many statistical tests, such as the t-test, ANOVA, and regression analysis, assume that the data are normally distributed.\n",
    "\n",
    "Quality Control: In manufacturing and quality control, the normal distribution is used to model the variability in product measurements, such as the length, weight, or thickness of a product. The distribution helps to identify whether the product meets the required specifications.\n",
    "\n",
    "Some real-life examples of the normal distribution are:\n",
    "\n",
    "1.Heights of people in a population\n",
    "2.Weights of products produced in a factory\n",
    "3.IQ scores of a population\n",
    "4.Test scores of students in a class\n",
    "5.Blood pressure readings of a population\n",
    "6.Annual rainfall amounts in a region\n",
    "7.Daily temperatures in a city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3d8a43",
   "metadata": {},
   "source": [
    "Q5: What is Bernaulli Distribution? Give an Example. What is the difference between Bernoulli\n",
    "Distribution and Binomial Distribution?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68cfd95d",
   "metadata": {},
   "source": [
    "The Bernoulli distribution is a discrete probability distribution that describes the outcome of a single binary experiment, where there are only two possible outcomes - success or failure. The distribution is named after the Swiss mathematician Jacob Bernoulli, who introduced the concept in the 17th century.\n",
    "\n",
    "The Bernoulli distribution is characterized by a single parameter, p, which represents the probability of success in the binary experiment. The probability mass function (PMF) of the Bernoulli distribution is:\n",
    "\n",
    "P(X = 1) = p\n",
    "P(X = 0) = 1 - p\n",
    "\n",
    "where X is a random variable representing the outcome of the binary experiment.\n",
    "\n",
    "For example, consider flipping a coin, where heads is considered a success and tails a failure. The Bernoulli distribution can be used to model the probability of getting heads, where p = 0.5.\n",
    "\n",
    "The key difference between Bernoulli distribution and binomial distribution is that Bernoulli distribution is used to model the outcome of a single binary experiment, whereas the binomial distribution is used to model the number of successes in a fixed number of independent Bernoulli trials.\n",
    "\n",
    "Binomial distribution is derived from multiple Bernoulli trials, and it is characterized by two parameters: n and p, where n is the number of trials and p is the probability of success in each trial. The probability mass function (PMF) of the binomial distribution is:\n",
    "\n",
    "P(X = k) = C(n, k) * p^k * (1-p)^(n-k)\n",
    "\n",
    "where:\n",
    "\n",
    "X is the number of successes in n independent Bernoulli trials\n",
    "k is the number of successes\n",
    "p is the probability of success in each trial\n",
    "(1-p) is the probability of failure in each trial\n",
    "C(n, k) is the number of ways to choose k successes from n trials, also known as the binomial coefficient or combination, and is defined as C(n, k) = n! / (k! * (n-k)!)\n",
    "\n",
    "For example, consider flipping a coin 10 times and counting the number of heads. The binomial distribution can be used to model the probability of getting k heads out of 10 flips, where n = 10 and p = 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad443ecb",
   "metadata": {},
   "source": [
    "Q6. Consider a dataset with a mean of 50 and a standard deviation of 10. If we assume that the dataset\n",
    "is normally distributed, what is the probability that a randomly selected observation will be greater\n",
    "than 60? Use the appropriate formula and show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f10638",
   "metadata": {},
   "source": [
    "We can use the standard normal distribution to calculate the probability of a randomly selected observation being greater than 60.\n",
    "\n",
    "First, we need to standardize the value of 60 using the formula:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where:\n",
    "\n",
    "x is the value of interest (in this case, x = 60)\n",
    "μ is the mean of the dataset (μ = 50)\n",
    "σ is the standard deviation of the dataset (σ = 10)\n",
    "z is the standard score or z-score, which represents the number of standard deviations that x is away from the mean\n",
    "Substituting the values, we get:\n",
    "\n",
    "z = (60 - 50) / 10 = 1\n",
    "\n",
    "Next, we look up the probability of z being less than 1 in the standard normal distribution table (or use a calculator). We get:\n",
    "\n",
    "P(Z < 1) = 0.8413\n",
    "\n",
    "Finally, we subtract this probability from 1 to get the probability of z being greater than 1:\n",
    "\n",
    "P(Z > 1) = 1 - P(Z < 1) = 1 - 0.8413 = 0.1587\n",
    "\n",
    "Therefore, the probability that a randomly selected observation from this dataset will be greater than 60 is approximately 0.1587 or 15.87%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a18641",
   "metadata": {},
   "source": [
    "Q7: Explain uniform Distribution with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc0580",
   "metadata": {},
   "source": [
    "The uniform distribution is a probability distribution that assigns equal probability to all values within a certain range. In other words, each value within the range is equally likely to occur, and there is no clustering of values around any particular point.\n",
    "\n",
    "For example, consider a scenario where we want to model the probability of a random number generator producing a value between 1 and 6 (inclusive), with each value having an equal probability of being generated. This scenario can be modeled using a uniform distribution with parameters a = 1 and b = 6 (the lower and upper bounds of the range).\n",
    "\n",
    "The probability density function (PDF) for a continuous uniform distribution with parameters a and b is given by:\n",
    "\n",
    "f(x) = 1 / (b - a), for a <= x <= b\n",
    "\n",
    "This means that the probability of generating any value within the range (1 to 6 in this example) is the same, and can be calculated as the area under the PDF curve between the lower and upper bounds of the range.\n",
    "\n",
    "For the discrete uniform distribution, which is used to model scenarios where the values are discrete (such as in rolling a die), the probability of each value is also equally likely and can be calculated as:\n",
    "\n",
    "P(X = k) = 1/n, for k = 1, 2, ..., n\n",
    "\n",
    "where n is the number of possible values, and k is any specific value within the range.\n",
    "\n",
    "The uniform distribution is useful in modeling situations where all outcomes are equally likely and where there is no prior information that would give a particular outcome a higher probability than others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232dfbec",
   "metadata": {},
   "source": [
    "Q8: What is the z score? State the importance of the z score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff2c5ef",
   "metadata": {},
   "source": [
    "The z-score (also called the standard score) is a measure of how many standard deviations a given data point is away from the mean of a distribution. It is calculated by subtracting the mean of the distribution from the data point, and then dividing the difference by the standard deviation of the distribution. The formula for calculating the z-score is:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where:\n",
    "\n",
    "x is the data point of interest\n",
    "μ is the mean of the distribution\n",
    "σ is the standard deviation of the distribution\n",
    "The z-score allows us to compare values from different distributions, and it provides a standardized way of interpreting data. By calculating the z-score, we can determine how many standard deviations a given data point is away from the mean, and we can then use standard normal distribution tables to find the probability of observing a value as extreme or more extreme than the given data point.\n",
    "\n",
    "The importance of the z-score is that it allows us to compare values from different datasets and interpret them in a standardized way. For example, if we want to compare the performance of two students in different classes who took different tests, we can calculate the z-score for each student based on the mean and standard deviation of their respective classes. This would allow us to compare the relative performance of the two students in a standardized way, regardless of the difficulty or variation in the two tests.\n",
    "\n",
    "The z-score is also used in statistical hypothesis testing, where it is used to calculate the p-value, which represents the probability of observing a test statistic as extreme or more extreme than the observed value, assuming that the null hypothesis is true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20080cb3",
   "metadata": {},
   "source": [
    "Q9: What is Central Limit Theorem? State the significance of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8779d5a1",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a fundamental result in probability theory and statistics. It states that, under certain conditions, the sum or average of a large number of independent and identically distributed (iid) random variables will be approximately normally distributed, regardless of the distribution of the original random variables. Specifically, as the sample size increases, the sampling distribution of the mean approaches a normal distribution with a mean equal to the population mean and a standard deviation equal to the population standard deviation divided by the square root of the sample size.\n",
    "\n",
    "In other words, the Central Limit Theorem implies that if we take many samples of the same size from a population and compute the mean of each sample, the distribution of those sample means will be approximately normal, even if the original population is not normally distributed. This makes the normal distribution a useful approximation for many real-world scenarios, and it is the foundation for many statistical methods and techniques.\n",
    "\n",
    "The significance of the Central Limit Theorem is that it provides a powerful tool for statistical inference and hypothesis testing. It allows us to use the normal distribution to estimate probabilities and make inferences about population parameters, such as the population mean or proportion, based on sample statistics. This is important because many real-world phenomena are not normally distributed, but the Central Limit Theorem provides a way to make probabilistic statements and statistical inferences about those phenomena. It also allows us to use statistical methods that rely on the normal distribution, such as the t-test, ANOVA, and regression analysis, in a wide range of situations, even when the underlying data is not normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a58038",
   "metadata": {},
   "source": [
    "Q10: State the assumptions of the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed3b51f",
   "metadata": {},
   "source": [
    "The Central Limit Theorem (CLT) is a powerful tool in statistics that allows us to make inferences about population parameters based on sample statistics. However, it is important to note that the CLT relies on certain assumptions. Here are the key assumptions of the Central Limit Theorem:\n",
    "\n",
    "1.Independence: The random variables in the sample must be independent of each other. This means that the value of one observation does not affect the value of another observation.\n",
    "\n",
    "2.Sample Size: The sample size must be sufficiently large. Although there is no strict rule for determining how large the sample size needs to be, a general guideline is that the sample size should be at least 30.\n",
    "\n",
    "3.Finite Variance: The population from which the sample is drawn must have a finite variance. This means that the population standard deviation should not be infinite.\n",
    "\n",
    "4.Identically Distributed: The random variables in the sample must be identically distributed. This means that they should have the same mean and variance.\n",
    "\n",
    "5.Random Sampling: The sample should be drawn randomly from the population. This means that each observation in the population should have an equal chance of being included in the sample.\n",
    "\n",
    "If these assumptions are met, then the Central Limit Theorem can be applied to the sample statistics to make inferences about population parameters. However, if any of these assumptions are violated, the Central Limit Theorem may not be applicable, and alternative methods should be used for statistical inference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
